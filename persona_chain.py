import sys
import asyncio
import os
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnableLambda
from langchain_groq import ChatGroq

# Windows event loop fix
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# Load GROQ API key
GROQ_API_KEY = os.getenv("groq_api_key")
if not GROQ_API_KEY:
    raise RuntimeError("GROQ_API_KEY not set in environment variables. Set it before running.")

# Prompt template â€” rich persona format like Lucas Mellor
prompt = PromptTemplate(
    template="""
You are an expert UX researcher. Based on the Reddit posts and comments below, generate a detailed user persona report.

The format should follow this structure:

------------------------
ğŸ‘¤ **Identity**
- **Name**:
- **Age**:
- **Occupation**:
- **Status**:
- **Location**:
- **Tier**: (e.g., Early Adopter, Mainstream)
- **Archetype**: (e.g., The Creator, The Explorer)
- **Traits**: (e.g., Practical, Adaptable, Spontaneous...)

ğŸ’¡ **Motivations**
- Convenience: (1-5 scale)
- Wellness:
- Speed:
- Preferences:
- Comfort:
- Dietary Needs:

ğŸ§  **Personality**  
(Indicate where they fall on each scale)
- Introvert â‡„ Extrovert  
- Sensing â‡„ Intuition  
- Thinking â‡„ Feeling  
- Judging â‡„ Perceiving  

ğŸ§â€â™‚ï¸ **Behaviour & Habits**  
Write 3-5 bullet points summarizing lifestyle patterns, digital usage, routines, etc.

ğŸ’¥ **Frustrations**  
Summarize key pain points. Use bullet points.

âœ… **Goals & Needs**  
Summarize aspirations and needs. Use bullet points.

ğŸ”— **Citations**
List **exact Reddit URLs** used in the analysis. Only include links found in the input content.

(If thereâ€™s anything unique or interesting about this person that doesnâ€™t fit in the above categories, include it in any relevant section.)

------------------------

Reddit User Content:
------------------------
{reddit_text}
""",
    input_variables=["reddit_text"]
)

# Groq LLaMA3 LLM
llm = ChatGroq(
    groq_api_key=GROQ_API_KEY,
    model_name="llama3-70b-8192",
    temperature=0.4
)

# LangChain pipeline
def build_chain():
    return (
        RunnableLambda(lambda input: {"reddit_text": input})
        | RunnableLambda(lambda d: {"prompt": prompt.format(**d)})
        | RunnableLambda(lambda d: {"structured": llm.invoke(d["prompt"]).content})
    )

chain = build_chain()
